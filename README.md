**Oryginalna dokumentacja repozytorium:**
[Original README](docs/README.md)

## Spis treÅ›ci
1. [Opis projektu](#opis-projektu)
2. [Przygotowanie Å›rodowiska symulacyjnego](#przygotowanie-Å›rodowiska-symulacyjnego)
3. [Implementacja algorytmu sterowania](#implementacja-algorytmu-sterowania)
4. [Algorytm detekcji znakÃ³w](#algorytm-detekcji-znakÃ³w)
5. [Uruchomienie](#uruchomienie)
6. [Przydatne komendy / informacje](#przydatne-komendy--informacje)

## Opis projektu
Projekt miaÅ‚ na celu zaprojektowanie i implementacjÄ™ autonomicznego samochodu dziaÅ‚ajÄ…cego w Å›rodowisku symulacyjnym ROS + Gazebo. W ramach projektu stworzono system umoÅ¼liwiajÄ…cy pojazdowi samodzielne poruszanie siÄ™ po drodze, wykrywajÄ…c i interpretujÄ…c elementy otoczenia na podstawie obrazu z kamery. Algorytm analizuje obraz z kamery zamontowanej na samochodzie, aby wykrywaÄ‡ liniÄ™ na Å›rodku jezdni. Na tej podstawie samochÃ³d dynamicznie wyznacza trajektoriÄ™ ruchu, utrzymujÄ…c siÄ™ w granicach wyznaczonego pasa. Detekcja znakÃ³w drogowych odbywaÅ‚a siÄ™ za pomocÄ… wytrenowanej wczeÅ›niej sieci neuronowej, dziÄ™ki czemu system jest w stanie rozpoznaÄ‡ rÃ³Å¼ne znaki, takie jak ograniczenia prÄ™dkoÅ›ci, znaki stopu czy ostrzeÅ¼enia.

## Przygotowanie Å›rodowiska symulacyjnego
W projekcie zostaÅ‚y wykorzystane projekty gotowy znaleziony w internecie:

- [Nathan Benson Park](https://app.gazebosim.org/OpenRobotics/fuel/models/nathan_benderson_park) - Gotowy Å›wiat zawierajÄ…cy ukÅ‚ad miasta z drogami z teskturami pasÃ³w.

- [Prius](https://app.gazebosim.org/OpenRobotics/fuel/models/Prius%20Hybrid%20with%20sensors) - Model pojazdu, ktÃ³ry bÄ™dzie testowany. 

- [Znak Stop](https://app.gazebosim.org/OpenRobotics/fuel/models/Stop%20Sign) - Model znaku, ktÃ³ry posÅ‚uÅ¼yÅ‚ jako model tekstury, w ktÃ³rym zmieniano grafikÄ™, aby stworzyÄ‡ inne znaki.

Wczytanie Å›wiata nastÄ™puje w pliku custom_city.sdf w nastÄ™pujÄ…cy sposÃ³b:
```bash
<include> 
  <uri> 
    model://nathan_benderson_park 
  </uri> 
</include>
```

W ten sposÃ³b, odnosimy siÄ™ do lokalizacji modelu samego modelu miasta, ktÃ³re zostaÅ‚o przez nas zmodyfikowane. KaÅ¼da tekstura wczytywana jest w ten sam sposÃ³b, podajÄ…c jej siatkÄ™ punktÃ³w, w ktÃ³rych ma siÄ™ znaleÅºÄ‡, teksturÄ™ oraz inne parametry takie jak fizycznÄ… kolizjÄ™ z innymi elementami otoczenia: 

```bash
<visual name="Road_visual"> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <geometry> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <mesh> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <uri>meshes/nb_park.dae</uri> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <submesh> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <name>Road</name> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <center>false</center> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ </submesh> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ </mesh> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ </geometry> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <material> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <diffuse>1.0 1.0 1.0</diffuse> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <specular>0.06 0.06 0.06</specular> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <pbr> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <metal> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <albedo_map>materials/textures/Road_Albedo.png</albedo_map> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <normal_map>materials/textures/Road_Normal.png</normal_map> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <roughness_map>materials/textures/Road_Roughness.png</roughness_map> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <environment_map>materials/textures/EnvMap.dds</environment_map>
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ </metal> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ </pbr> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ </material> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ </visual>  
```
Do mapy rÃ³wnieÅ¼ dodano znaki, tak aby przybraÅ‚y moÅ¼liwie realne rozmieszczenie znakÃ³w w mieÅ›cie. WÅ›rÃ³d dodanych znakÃ³w sÄ…: 

- Znak stopu 
- Znaki dopuszczalnej prÄ™dkoÅ›ci 
- Nakazy jazdy, skrÄ™tu 
- Znaki pierwszeÅ„stwa 
- Znak przejÅ›cia dla pieszych 

Znaki sÄ… wczytywane w ten sam sposÃ³b jak mapa oraz zmienione, tak aby miaÅ‚y rÃ³Å¼ne grafiki. 

```bash
<include> 
â€¯ â€¯ â€¯ <uri>model://models/Signs/Priority_sign</uri> 
â€¯ â€¯ â€¯ <name>Priority Sign</name> 
â€¯ â€¯ â€¯ <pose>-134.9530029296875 973.00592041015625 5 0 0 0</pose> 
â€¯ â€¯ </include> 
 
<?xml version="1.0" ?> 
<sdf version="1.5"> 
â€¯ <model name="Priority Sign"> 
â€¯ â€¯ <static>true</static> 
â€¯ â€¯ <link name="link"> 
â€¯ â€¯ â€¯ <collision name="collision"> 
â€¯ â€¯ â€¯ â€¯ <geometry> 
â€¯ â€¯ â€¯ â€¯ â€¯ <mesh> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <scale>10 10 10</scale> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <uri>model://models/Signs/Priority_sign/meshes/priority_sign.dae</uri> 
â€¯ â€¯ â€¯ â€¯ â€¯ </mesh> 
â€¯ â€¯ â€¯ â€¯ </geometry> 
â€¯ â€¯ â€¯ </collision> 
â€¯ â€¯ â€¯ <visual name="visual"> 
â€¯ â€¯ â€¯ â€¯ <geometry> 
â€¯ â€¯ â€¯ â€¯ â€¯ <mesh> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <scale>10 10 10</scale> 
â€¯ â€¯ â€¯ â€¯ â€¯ â€¯ <uri>model://models/Signs/Priority_sign/meshes/priority_sign.dae</uri> 
â€¯ â€¯ â€¯ â€¯ â€¯ </mesh> 
â€¯ â€¯ â€¯ â€¯ </geometry> 
â€¯ â€¯ â€¯ </visual> 
â€¯ â€¯ </link> 
â€¯ </model> 
</sdf> 
```
WaÅ¼nym elementem jest podanie poprawnej Å›cieÅ¼ki do mapy punktÃ³w modelu okreÅ›lonym w sekcji <uri> i podanie niej odpowiedniej grafiki:

```bash
<image id="Speed_30_tga">
â€¯ â€¯ â€¯ <init_from>../materials/textures/priority.png</init_from>
</image> 
```
Model samochodu nie zostaÅ‚ w Å¼aden sposÃ³b zmodyfikowany, tylko wczytany wprost z pliku wraz z okreÅ›leniem miejsca, w ktÃ³rym ma siÄ™ pojawiaÄ‡ na mapie wzglÄ™dem centrum.

## Implementacja algorytmu sterowania
W projekcie do sterowania pojazdem wykorzystano kontroler Stanleya. Jest to jeden z popularnych algorytmÃ³w uÅ¼ywanych do sterowania autonomicznymi pojazdami. Jego gÅ‚Ã³wnym celem jest minimalizacja odchylenia pojazdu od zaplanowanej trajektorii oraz utrzymanie poprawnej orientacji pojazdu wzglÄ™dem tej trajektorii.

![Schemat okreÅ›lajÄ…cy najwaÅ¼niejsze zmienne dla kontrolera Stanleya](images/stanley.png)

Kontroler Stanley zostaÅ‚ zaimplementowany jako czÄ™Å›Ä‡ funkcji motion_controller. Algorytm wykorzystuje bieÅ¼Ä…cy stan pojazdu oraz punkty trajektorii do obliczenia kÄ…ta skrÄ™tu i wysyÅ‚ania odpowiednich komend prÄ™dkoÅ›ci do pojazdu.

```bash
def motion_controller(self, waypoints=None, target_vel=0.0):
    if waypoints is not None:
        c_x = waypoints[0]
        c_y = waypoints[1]
        c_yaw = waypoints[2]

        delta, self.target_idx = stanley_control(self.state, c_x, c_y, c_yaw, self.target_idx)
        # turningRadius = L * np.tan(delta)
        turningRadius = L / np.sin(delta)
        target_yaw_rate = self.state.v / turningRadius

        self.send_setpoints(target_vel, target_yaw_rate)

        delta_conv = np.sign(delta)*(90 - np.rad2deg(np.abs(delta)))
        self.get_logger().info(f"v: {target_vel}, delta: {delta_conv}")
    else:
        target_yaw_rate = 0.0
        self.send_setpoints(target_vel, target_yaw_rate)
```

Kluczowe kroki:
- Obliczenie kÄ…ta skrÄ™tu ğ›¿: Funkcja stanley_control wyznacza kÄ…t skrÄ™tu na podstawie bieÅ¼Ä…cego stanu pojazdu oraz trajektorii.
- Wyznaczenie prÄ™dkoÅ›ci kÄ…towej: PrÄ™dkoÅ›Ä‡ kÄ…towa ğœ“' jest zaleÅ¼na od prÄ™dkoÅ›ci liniowej pojazdu ğ‘£ oraz promienia skrÄ™tu.
- Publikacja komend: Komendy prÄ™dkoÅ›ci liniowej i kÄ…towej sÄ… wysyÅ‚ane do napÄ™du pojazdu za pomocÄ… ROS /cmd_vel.

Trajektoria jest interpolowana za pomocÄ… funkcji calc_spline_course z biblioteki cubic_spline_planner. Algorytm generuje punkty trajektorii oraz odpowiadajÄ…ce im kÄ…ty orientacji:

```bash
c_x, c_y, c_yaw, _, _ = cubic_spline_planner.calc_spline_course(x, y, ds=0.1)

self.waypoints = (c_x, c_y, c_yaw)
self.target_idx, _ = calc_target_index(self.state, c_x, c_y)

self.state.x = 0.0
self.state.y = 0.0
self.state.yaw = 0.0
```

## Algorytm detekcji znakÃ³w
Algorytm detekcji znakÃ³w drogowych zostaÅ‚ zaprojektowany w celu identyfikacji znakÃ³w na obrazie z kamery przedniej pojazdu. Proces obejmuje wykrywanie obszarÃ³w z potencjalnymi znakami drogowymi, klasyfikacjÄ™ ich na odpowiednie kategorie oraz przekazywanie wynikÃ³w w czasie rzeczywistym.

Przed analizÄ… obraz jest konwertowany z formatu ROS na format zgodny z OpenCV przy uÅ¼yciu biblioteki cv_bridge:

```bash
frame = self.bridge.imgmsg_to_cv2(msg, desired_encoding="bgr8")
```

Zidentyfikowane obszary sÄ… klasyfikowane przy uÅ¼yciu wczytanego, wczeÅ›niej wytrenowanego modelu sieci neuronowej:

```bash
self.model = tf.saved_model.load(
    "/home/developer/ros2_ws/src/autonomous_vehicle/autonomous_vehicle/good_model")
```

Przed klasyfikacjÄ…, fragment obrazu jest przetwarzany:

- Skalowanie do wymiaru 30x30 pikseli.
- Normalizacja wartoÅ›ci pikseli do zakresu [0, 1].
- Dodanie wymiaru dla batcha.

Model zwraca etykietÄ™ oraz poziom pewnoÅ›ci:

```bash
output = self.model.signatures["serving_default"](input_tensor)
predictions = output["output_0"].numpy()
pred = np.argmax(predictions, axis=1)[0]
confidence = np.max(predictions)
```

Dopasowana etykieta jest pobierana z predefiniowanego sÅ‚ownika:

```bash
sign = self.class_labels[pred + 1]
```

## Uruchomienie
Po sklonowaniu repozytorium i zbudowaniu dockera naleÅ¼y wykonaÄ‡ poniÅ¼sze komendy.

Zbudowanie paczek:
```bash
colcon build --symlink-install
colcon build --packages-select autonomous_vehicle
```

Uruchomienie Å›rodowiska:
```bash
source install/setup.bash
```

Uruchomienie pliku launch:
```bash
ros2 launch autonomous_vehicle/launch/auto.launch.py
```

Uruchomienie pliku node do wyÅ›wietlania obrazÃ³w z kamer:
```bash
ros2 run autonomous_vehicle helper_node
```

## Przydatne komendy / informacje:
Bridge ROS-Gazebo:
```bash
ros2 run ros_gz_bridge parameter_bridge --ros-args -p config_file:=ros_gz_bridge.yaml
```
ÅšcieÅ¼ka do modeli gazebo pobieranych z internetu:
```bash
$HOME/.gz/fuel/
```
RViz:
```bash
ros2 run rviz2 rviz2
```
Przy wizualizacji chmury punktÃ³w lidaru trzeba to umieÅ›ciÄ‡ w "Global Options / Fixed Frame"
```bash
prius_hybrid_sensors/sensors/center_laser_sensor
```
